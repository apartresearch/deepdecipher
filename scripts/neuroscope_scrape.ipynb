{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"solu-1l      \",\n",
    "    \"gelu-1l      \",\n",
    "    \"solu-2l      \",\n",
    "    \"gelu-2l      \",\n",
    "    \"solu-3l      \",\n",
    "    \"gelu-3l      \",\n",
    "    \"solu-4l      \",\n",
    "    \"gelu-4l      \",\n",
    "    \"solu-6l      \",\n",
    "    \"solu-8l      \",\n",
    "    \"solu-10l     \",\n",
    "    \"solu-12l     \",\n",
    "    \"gpt2-small   \",\n",
    "    \"gpt2-medium  \",\n",
    "    \"gpt2-large   \",\n",
    "    \"gpt2-xl      \",\n",
    "    \"solu-1l-pile \",\n",
    "    \"solu-4l-pile \",\n",
    "    \"solu-2l-pile \",\n",
    "    \"solu-6l-pile \",\n",
    "    \"solu-8l-pile \",\n",
    "    \"solu-10l-pile\",\n",
    "    \"pythia-70m    \",\n",
    "    \"pythia-160m   \",\n",
    "    \"pythia-350m   \",\n",
    "]\n",
    "models = [model.strip() for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for model in models:\n",
    "        neuron_page = get_neuron_page(model, 0, 0)\n",
    "        open(f\"../data/{model}.html\", \"w\").write(neuron_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuronav as nrnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrnv.debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alber\\miniconda3\\envs\\neuronav\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformer_lens\n",
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model solu-1l into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"solu-1l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48262\n",
      "['ocardial', ' patriotic', ' enlightenment', ' centimeters', 'iffany', ' Lindsey', ' Sacred', ' Omaha', ' elevate', 'Bir', ' annulus', 'Cold', 'SQ', 'OURCES', ' Semi', ' dormant', ' Hitch', ' Lorenzo', ' Pep', ' Bitmap', ' ventured', ' ejemplo', 'Aye', ' disproportionate', 'istes', 'mw', 'iegel', 'araoh', ' mycket', 'mkdir', ' Cys', ' liberated', ' oppressive', ' groaned', 'ynote', 'Translation', ' habl', ' balloons', ' bim', ' servic', ' Aircraft', ' curs', ' glimps', ' relegated', ' Ramos', 'CURRENT', ' elaborated', ' radiant', ' remake', ' weddings', ' andra', ' Cary', 'izability', ' boarded', 'анд', 'ете', 'acm', ' StringBuilder', 'needs', ' Renew', ' justices', 'appendix', 'arching', ' airst', ' Revised', 'jets', ' grup', 'bilt', ' sial', ' toddler', 'itons', ' PIP', ' Tus', 'ibrated', ' fortified', 'ferenced', ' Outcomes', '                        ', '                       ', '                      ', '                     ', '                    ', '                   ', '                  ', '                 ', '                ', '               ', '              ', '             ', '            ', '           ', '          ', '         ', '        ', '       ', '      ', '     ', '    ', '   ', '  ']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = model.tokenizer\n",
    "tokens = [tokenizer.decode(token_id) for token_id in range(len(tokenizer))]\n",
    "print(len(tokens))\n",
    "print(tokens[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[None]\n",
      " ctx\n"
     ]
    }
   ],
   "source": [
    "print(\" .\" in tokens)\n",
    "print(tokenizer.convert_tokens_to_ids([\" .\"]))\n",
    "print(tokens[20298])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1, 20298]])\n"
     ]
    }
   ],
   "source": [
    "print(model.to_tokens(\" ctx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neuronav as nrnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    nrnv.scrape_layer_to_files(\"data\", \"solu-1l\", tokens, 0, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuronav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
